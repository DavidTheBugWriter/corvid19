---
title: "R web scraping"
output: html_notebook
---
```{r}
    # https://www.datacamp.com/community/tutorials/r-web-scraping-rvest
library('xml2')
library('rvest')
library('stringr')
    
    
scrape<-function()
    {
    url<-'https://gov.uk/guidance/coronavirus-covid-19-information-for-the-public'
    
    pat_all<-"^As of 9am on (.*2020), (.*) people .* ([0-9,]+) were confirmed( as)? positi"
    pat_died<-"^As of 5pm on (.*2020), .* coronavirus, ([0-9,]+) have died."
    
    covid_data_html <- read_html(url) #turn page to xml
    covid_xml<-html_nodes(covid_data_html, '#number-of-cases-and-deaths') 
    
    all_tests_raw_text<-html_text(xml_siblings(covid_xml)[3])
    deaths_raw_text<-html_text(xml_siblings(covid_xml)[4])
    
    all_text<-str_match(all_tests_raw_text,pat_all)
    death_text<-str_match(deaths_raw_text,pat_died)
    
    scrape<-data.frame(
     report_date=as.Date(all_text[2],"%d %B %Y"),
     tested=as.integer(gsub(",","",all_text[3])),
     pos_tested=as.integer(gsub(",","",all_text[4])),
     died_date=as.Date(death_text[2],"%d %B %Y"),
     died=as.integer(gsub(",","",death_text[3]))
    )
    return(scrape)
    }
    
    scr<-scrape()
    scr
```

